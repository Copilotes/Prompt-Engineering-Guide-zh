提示工程是一种相对较新的学科，用于开发和优化提示，以有效地使用语言模型（LM）进行各种应用和研究主题。提示工程技能有助于更好地理解大型语言模型（LLM）的能力和局限性。研究人员使用提示工程来改善LLMs在各种常见和复杂任务上的能力，如问答和算术推理。开发人员使用提示工程来设计与LLMs和其他工具进行交互的稳健而有效的提示技术。

本指南介绍标准提示的基础知识，提供了如何使用提示与大型语言模型（LLMs）进行交互和指导的大致思路。

所有示例都是使用text-davinci-003（在OpenAI的游乐场上）进行测试，除非另有说明。它使用默认配置，例如temperature=0.7和top-p=1

Topic:
- [Basic Prompts](#basic-prompts)
- [A Word on LLM Settings](#a-word-on-llm-settings)
- [Standard Prompts](#standard-prompts)
- [Prompt Elements](#elements-of-a-prompt)
- [General Tips for Designing Prompts](#general-tips-for-designing-prompts)

---

基础提示
使用提示，您已经可以完成很多工作，但结果的质量取决于您提供的信息量。提示可以包含信息，如传递给模型的“指令”或“问题”，以及包括其他详细信息，例如“输入”或“示例”。

下面是一个简单提示的基本示例：

*提示*

![image](https://user-images.githubusercontent.com/16472262/221343493-777fa04e-2067-4112-847c-a969a375f603.png)

*输出*


![image](https://user-images.githubusercontent.com/16472262/221343540-dc7c1811-1ec7-4414-90a8-d6597f7a70d9.png)

正如您所看到的，语言模型输出了一系列字符串，这些字符串在给定上下文“天空是”时是有意义的。输出可能出乎意料，或者远离我们想要完成的任务。

这个基本示例也凸显了提供更多上下文或指令是必要的。

我们来试着改进一下：

*提示：*

![image](https://user-images.githubusercontent.com/16472262/221343599-67bbf9b5-2c9a-4424-a221-b57f1dddf82f.png)

*输出：*
![image](https://user-images.githubusercontent.com/16472262/221343615-368fceaa-2d7d-4019-ab43-631e9b86636e.png)

。
这样是不是更好了？我们告诉模型完成句子，所以结果看起来更好，因为它完全按照我们告诉它做的事情（“完成句子”）。这种设计最佳提示来指导模型执行任务的方法被称为提示工程。

上面的示例是当前LLMs所能做到的基本示例。今天的LLMs能够执行各种高级任务，从文本摘要到数学推理到代码生成等等。

---
LLM设置的注意事项
在使用提示时，您将通过API或直接与LLM交互。您可以配置一些参数以获取不同的提示结果。

Temperature - 简而言之，温度越低，结果越确定，因为始终选择最有可能的下一个标记。增加温度可能导致更多的随机性，鼓励更多的多样性或创造性输出。我们实质上是增加其他可能标记的权重。在应用方面，对于类似基于事实的问答，我们可能希望使用较低的温度，以鼓励更加真实和简明的响应。对于诗歌生成或其他创意任务，增加温度可能是有益的。

Top_p - 类似地，使用温度的一种采样技术，称为Nucleus采样，可以控制模型在生成响应时的确定性程度。如果您正在寻找确切和事实性答案，请保持较低。如果您正在寻找更多样化的答案，请将其增加到较高的值。

一般建议只改变其中一个而不是两个。

在开始一些基本示例之前，请记住，您的结果可能会因所使用的LLM版本而异。

---
我们以上尝试了一个非常简单的提示。标准提示具有以下格式：


<问题>？
这可以格式化为QA格式，这是许多QA数据集中的标准，如下所示：


Q：<问题>？
A： 
鉴于上述标准格式，一种流行且有效的提示技术是称为few-shot提示，其中我们提供示例。few-shot提示可以格式化为以下方式：


<问题>？
<答案>

<问题>？
<答案>

<问题>？
<答案>

<问题>？

```


你已经可以猜到它的QA格式版本如下所示

```
Q：<问题>？
A：<答案>

Q：<问题>？
A：<答案>

Q：<问题>？
A：<答案>

Q：<问题>？
A：

```

请记住，不需要使用QA格式。格式取决于所处理的任务。例如，您可以执行一个简单的分类任务，并按以下方式给出演示任务的示例：

*提示:*
```
这很棒！ // 积极
这很糟糕！ // 消极
哇，那部电影很棒！ // 积极
这是多么糟糕的一场演出！ //

```

*输出:*
```
负面
```

Few-shot提示使得在上下文中学习成为可能，这是指语言模型仅通过几个示例就能够学习任务。我们将在即将发布的指南中更多地了解到它的应用。
---
## 提示的元素
随着我们涵盖越来越多的提示工程示例和应用，您会发现提示由以下某些元素组成。

一个提示可以包含以下组件：

指令 - 您想让模型执行的特定任务或指令
上下文 - 可以包含外部信息或其他上下文，以指导模型提供更好的响应
输入数据 - 我们要查找响应的输入或问题
输出指示器 - 表示输出类型或格式的指示器。
并非所有组件都必须在提示中出现，格式取决于具体任务。我们将在即将发布的指南中提供更多具体的示例。

---
## General Tips for Designing Prompts

Here are few some tips to keep in mind while you are designing your prompts:

###设计提示的一般性技巧
在设计提示时，请记住以下一些技巧：

指令
您可以使用指令来设计各种简单任务的有效提示，如“写”，“分类”，“摘要”，“翻译”，“排序”等，指示模型实现您的意图。

请记住，您还需要进行大量实验，以查看哪种指令和关键字、上下文和数据的组合最适合您特定的用例和任务。通常情况下，上下文与您要执行的任务越相关和具体，越好。我们将在即将发布的指南中详细介绍采样和添加更多上下文的重要性。

其他人建议将指令放置在提示开头。还建议使用一些清晰的分隔符（如“###”）来分隔指令和上下文。

例如：

*提示:*
```
### 指令 ###
"hello!" 的西班牙语翻译是 "¡hola!"。

Text: "hello!"
```

*Output:*
```
¡Hola!
```

### 具体性

对于你想让模型执行的指令和任务，要非常具体。提示越描述性和详细，结果就会越好。当你想要特定的输出或生成风格时，这一点尤其重要。没有特定的标记或关键字可以导致更好的结果。拥有良好的格式和描述性的提示更为重要。事实上，提供示例在提示中非常有效，以便在特定格式中获得所需的输出。

例如，我们来尝试一个简单的提示，从一段文本中提取特定信息。

*提示:*
```
格式：

地点：地点列表用逗号分隔

Prompt:

提取以下文本中的地点名称。

期望输出格式：

地点：用逗号分隔的地点名称列表

输入： "虽然这些发展对研究人员来说是鼓舞人心的，但仍有很多未解之谜。位于里斯本的未知战斗中心的神经免疫学家亨利克·维加-费尔南德斯（Henrique Veiga-Fernandes）表示：“我们经常在大脑和我们在外围看到的效果之间有一个黑匣子。如果我们想在治疗环境中使用它，我们实际上需要了解机制。”"

输出:

地点：里斯本
```

*输出:*
```
地点：葡萄牙里斯本的香帕利莫德未知中心
```

输入文本来源于 [this Nature article](https://www.nature.com/articles/d41586-023-00509-z).

###避免不准确性

按照上述提示，提供详细信息和改善格式是很容易陷入刻意创造提示和潜在创建不准确描述的陷阱。直接和具体描述通常会更好。这里的类比非常类似于有效沟通-越直接，传达的信息就越有效。

例如，您可能有兴趣生成一份购买清单，以准备烧烤。您可以尝试以下提示：
```
请解释“prompt engineering”的概念。简要说明，只用几句话，不要过于描述。
```

上面的提示文本并没有说明要用多少句话和什么样的风格，可能会得到一些不错的回应，但更好的提示文本应该非常具体、简明扼要，直截了当。比如：

```
使用2-3句话向高中生解释提示工程的概念。
```

### “做还是不做？”
在设计提示时，另一个常见的提示是避免说“不要做什么”，而是说“要做什么”。这样可以更具体地关注细节，从而使模型的响应更好。

这是一个电影推荐聊天机器人的示例，它失败了，因为我在指令中专注于“不要做什么”。
*提示:*
```
这是一个向顾客推荐电影的代理程序。请勿询问兴趣或个人信息。

顾客：请根据我的兴趣推荐一部电影。
代理程序：
```

*输出:*
```
当然，我可以根据你的兴趣为你推荐一部电影。你想看什么类型的电影？你喜欢动作片、喜剧片、爱情片还是其他类型的电影？
```

这里是一个更好的提示：

*提示:*
```
以下是一名向客户推荐电影的代理人。代理人负责从全球热门电影中推荐一部电影。它应该避免询问用户的偏好和个人信息。如果代理人没有电影推荐，它应该回复“抱歉，今天找不到电影推荐。”

顾客：请根据我的兴趣推荐一部电影。
代理人：抱歉，我不能根据你的兴趣推荐电影。我可以向您推荐全球热门电影中的一部电影。
```

*输出:*
```
抱歉，我没有关于你兴趣的信息。但是，这是目前全球热门电影的列表：[电影列表]。希望你能找到自己喜欢的！
```

以下一些示例来自于《OpenAI API提示词工程最佳实践》文章。 ["Best practices for prompt engineering with OpenAI API" article.](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)


---
[下一部分 (Basic Prompting)](./prompts-basic-usage.md)
